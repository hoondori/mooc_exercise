{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 18 State Space Models\n",
    "\n",
    "\n",
    "## 18.3.2 Kalman smoothing algorithm\n",
    "\n",
    "* kalman filter\n",
    "  * p(z_t|y_1:t), no future data, online like tracking\n",
    "* kalman smoothing\n",
    "  * p(z_t|y_1:T), with future data, offline\n",
    "  * 미래 데이터 활용으로 인해 불확실성 감소\n",
    "    * 아래 (c) 처럼 neighbor가 많은 부분은 불확실성이 감소\n",
    "    * 시작과 끝부분은 상대적으로 neighbor가 적어서 감소 효과가 적다\n",
    "\n",
    "![](./images/ch18/19.png) \n",
    "\n",
    "\n",
    "### notation recall\n",
    "\n",
    "![](./images/ch18/21.png) \n",
    "\n",
    "\n",
    "### algorithm\n",
    "\n",
    "* HMM의 forward-backward 알고리즘과 유사\n",
    "  * 즉 UGM에서의 message passing의 원리\n",
    "  * 왼쪽에서 시작해서 오른쪽으로 그래프 끝까지 전파, p(z_T|y_1:T)\n",
    "  * 이를 다시 거꾸로 역전파(future back to the past)\n",
    "  * 정방향 정보와 역방향 정보를 결합\n",
    "* HMM의 forward-backward 와의 차이점 \n",
    "  * HMM의 backward는 forward를 선행하지 않고 단독으로 진행 가능\n",
    "    * 그 과정중 observation data 필요\n",
    "  * kalman smoothing에서는 forward가 반드시 선행되야 함. \n",
    "    * 반면 observation data 필요없고, 정방향 정보만 필요\n",
    "\n",
    "![](./images/ch18/20.png) \n",
    "\n",
    "### derivation - skip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.4 Learning for LG-SSM\n",
    "\n",
    "* how to estimate parameters of of LG-SSM, namely, A,C,Q,R below\n",
    "  * in control theory, called system identification\n",
    "\n",
    "![](./images/ch18/02.png)\n",
    "\n",
    "* special case - well known A, C \n",
    "  * ex) time series forcasting, or physical state estimation\n",
    "  * 단지 Q와 R만 추정하면 된다. \n",
    "\n",
    "### Identifiability and numerical stability\n",
    "\n",
    "* without loss of generality\n",
    "  * assume Q = I => noise 는 A로 적절히 표현 가능 \n",
    "  * assume R to be diagonal => reduce DOF => improve numerical stability\n",
    "* eigenvalue of A\n",
    "  * if no system noise, and eigenvalue greater than 1 => blow up\n",
    "  * all eigenvalues be less than 1 with non-zero noise\n",
    "\n",
    "![](./images/ch18/22.png)\n",
    "\n",
    "### EM for LG-SSM\n",
    "\n",
    "* HMM 의 Baum-welch 와 유사, \n",
    "  * 참고 : https://web.stanford.edu/~lmackey/stats306b/doc/stats306b-spring14-lecture11_scribed.pdf\n",
    "  \n",
    "![](./images/ch18/23.png)\n",
    "![](./images/ch18/24.png)\n",
    "![](./images/ch18/25.png)\n",
    "\n",
    "\n",
    "### Subspace methods for LG-SSM\n",
    "\n",
    "* EM 방식의 단점\n",
    "  * 초기 parameter 추정\n",
    "* Subspace methods for system identification \n",
    " * project y onto subspace of z, and using PCA, identify subspace\n",
    " * https://www.youtube.com/watch?v=EMdrHvYd_Zs \n",
    " * https://simsee.org/simsee/biblioteca/Springer,%20Subspace%20Methods%20For%20System%20Identification%20(2005)%20Ddu%20Lotb.pdf \n",
    "\n",
    "### Baysian methods for LG-SSM\n",
    "\n",
    "* offline baysian alternatives\n",
    "  * Variational Bayes EM (Beal 2003)\n",
    "  * Blocked Gibbs Sampling (Carter 1994)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.5 Approximate online inference for non-linearm non-gaussian SSMs\n",
    "\n",
    "* 지금까지는 easy-case\n",
    "  * linear and gauusian model\n",
    "  * gaussian noise\n",
    "* 일반적으로는 \n",
    "  * non-linear, non-gaussian model\n",
    "  * non-gaussian noise\n",
    "  \n",
    "\n",
    "### 18.5.1 Extended Kalman filter(EKF)\n",
    "\n",
    "* 약간 어려운 case\n",
    "  * non-liear model\n",
    "  * gassuian nose\n",
    "* approximate inference\n",
    "  * approximate the posterior by a Gaussian\n",
    "  * Y=f(X)\n",
    "    * X be gaussian\n",
    "    * f be non-linear function\n",
    "    * Y be approximate gaussian\n",
    "\n",
    "* 기본 아이디어\n",
    "  * 각 시점에서 선형 근사화(first-order taylor approx)\n",
    "  * 그런다음 standard kalman filter 적용\n",
    "\n",
    "![](./images/ch18/26.png)  \n",
    "![](./images/ch18/27.png)\n",
    "\n",
    "![](./images/ch18/28.png)\n",
    "![](./images/ch18/29.png)\n",
    "![](./images/ch18/30.png)\n",
    "\n",
    "* 잘 작동하지 않는 경우 \n",
    "  * prior covariancerk 너무 펑퍼짐할 때, 초기부터 많은 probability mass를 linearized 과정 중에 유실\n",
    "  * mapping function이 nonlinear near the current mean 일 때 \n",
    "\n",
    "![](./images/ch18/31.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.5.2. unscented kalman filter(UKF)\n",
    "\n",
    "* better version of EKF \n",
    "* approximate a Gaussian than to approximate a function\n",
    "  * EKF : approximate a function as linear, then pass a gaussian through it\n",
    "  * UKF : choose sigma points, and pass through function, and fit a gaussian to the transformed points\n",
    "  \n",
    " \n",
    "#### Unscented transform \n",
    "\n",
    "* assume \n",
    "  * p(x) is gassuian\n",
    "  * y = f(x) as non-linear\n",
    "* steps\n",
    "  * choose 2d + 1 sigma points in x-domain such that it represent well underlying dist. i.e gaussian\n",
    "  * pass through non-linear function\n",
    "  * new mean and convariance are computed on transformed points\n",
    "\n",
    "![](./images/ch18/32.png)\n",
    "\n",
    "![](./images/ch18/33.png)\n",
    "![](./images/ch18/34.png)\n",
    "\n",
    "![](./images/ch18/35.png)\n",
    "\n",
    "#### unscented kalman filter\n",
    "\n",
    "* aprroximate two non-gassuaian dist by two unscented transforms\n",
    "* first is prediction step\n",
    "\n",
    "![](./images/ch18/36.png)\n",
    "\n",
    "* second is approximate local evidence\n",
    "\n",
    "![](./images/ch18/37.png)\n",
    "\n",
    "* last is update (error-based correction like KF)\n",
    "\n",
    "![](./images/ch18/38.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparision of KF, EKF, UKF, Particle filter\n",
    "\n",
    "![](./images/ch18/39.png)\n",
    "![](./images/ch18/40.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.5.3. Assumed density filtering (ADF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.6 Hybrid discrete/continuous SSMs\n",
    "\n",
    "* hidden state가 discrete와 continous가 mixing 되어 있는 경우\n",
    "* HMM + LG-SSM => switching lineary dynamic system\n",
    "\n",
    "![](./images/ch18/41.png)\n",
    "\n",
    "### Inference\n",
    "\n",
    "* unfortunetely, is is intractable\n",
    "* exponential explosion of mode\n",
    "  * prior (2 mixG) -> 4 mixG -> 8 mixG\n",
    " \n",
    "![](./images/ch18/42.png) \n",
    "\n",
    "* how to approximate\n",
    "  * prune low prob of trajectories in discrete-tree\n",
    "  * sample in tree (section 23.6)\n",
    "  * Use ADF : approimate large mixG with small mixG\n",
    "  \n",
    "\n",
    "### A gaussian sum filter for switching SSMs\n",
    "\n",
    "* approximate the belief state at each step by mixture of gaussians\n",
    "* implemented by running K kalman filters\n",
    "* algorithm\n",
    "  * given K mixG\n",
    "  * pass through K different KF, and acquire K^2 beliefs (explode)\n",
    "  * collapse K mixG into single gaussian\n",
    "\n",
    "![](./images/ch18/43.png) \n",
    "\n",
    "* how to merge mixture of gassian into single gaussian\n",
    "  * by moment matching (only match first/second moment)\n",
    "  * weak marginalization\n",
    "  \n",
    "![](./images/ch18/44.png)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.6.2 Application: data association and multi-target tracking\n",
    "\n",
    "* 레이더 상의 K개의 물체를 K'개의 detect event를 통해 tracking\n",
    "* K > K' 인 경우 : occlusion or missed detected\n",
    "* K < K' 인 경우 : due to clutter or false alarms\n",
    "* data association 문제\n",
    "  * 서로 다른 cardinality의 z 와  y를 상호 연관시키는 문제\n",
    "\n",
    "![](./images/ch18/45.png) \n",
    "\n",
    "* Hungarian alforithm \n",
    "  * http://www.mathcs.emory.edu/~cheung/Courses/323/Syllabus/Transportation/algorithm.html\n",
    "  * typically, association reprsent K x K' matrix\n",
    "  * add dummy => N x N, where N = max(K,K')\n",
    "  * explain all false alarms, missed detections\n",
    "  * compute bypartite matching, O(N^3)\n",
    "* KF update does not work on dummy observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.6.3 Application: Falut diagnosis\n",
    "\n",
    "* two-tank model\n",
    "* benchmark in falut-diagnosis community\n",
    "* latent \n",
    "  * pressure inside tank(continuous)\n",
    "  * resistence in pipe (continous)\n",
    "  * whether or not of resistence failures (discrete)\n",
    "* measurements\n",
    "  * flow in-out \n",
    "  * whether or not of measurement failures (discrete)\n",
    "\n",
    "![](./images/ch18/46.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
