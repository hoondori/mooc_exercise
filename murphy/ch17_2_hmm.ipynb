{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5 Learning for HMMs\n",
    "---\n",
    "* 모델 파라미터를 추정하는 것\n",
    "  * inital state probabilites\n",
    "  * state transition matrix, A = p(z_t|z_t-1)\n",
    "  * observation probability, B = p(x_t | z_t)\n",
    "* 두 가지 case\n",
    "  * 상태열, z_1:T 를 안다고 가정할 때 <- 극단적인 쉬운 상황\n",
    "  * 상태열을 모르는 상황 <- 일반적\n",
    "  \n",
    "\n",
    "### 17.5.1 Training with fully observed data\n",
    "---\n",
    "* 상태열을 안다고 가정할 때\n",
    "* 초기 상태 확률과 천이 확률은 markov chain MLE와 동일하게 구할 수 있음 (17.2.2.1)\n",
    "\n",
    "![](./images/ch17/32.png) \n",
    "![](./images/ch17/33.png) \n",
    "\n",
    "* 관측 확률은 어떤 관측 모델(ex. mulltinulli, gaussian)이냐에 따라 달라진다.\n",
    "* 관측 모델이 multinoulli일 경우는 아래와 같다. \n",
    "\n",
    "![](./images/ch17/34.png) \n",
    "\n",
    "* 관측 모델이 gaussian 일 경우는 아래와 같다. \n",
    "\n",
    "![](./images/ch17/35.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation-Maximization 리뷰 (11.4)\n",
    "---\n",
    "### 언제 사용?\n",
    "* full data가 주어지면 일반적으로 ML/MAP 구하는 건 누워서 떡먹기\n",
    "* missing data나 latent variable가 있을 때는 매우 어려워짐\n",
    "* 이럴 때 사용하는 게 EM\n",
    "  * iterative, close-form update (hopefully)\n",
    "\n",
    "### 기본 아이디어\n",
    "* 아래처럼 일반적으로 data log likelihood를 최대화하는 파라미터를 구하고 싶다.\n",
    "* 하지만 latent variable이 있고, 이것이 log sum 형태여서는 optimize하기 쉬운 형태가 아님\n",
    "\n",
    "![](./images/ch17/36.png) \n",
    "\n",
    "* 대신 아래처럼 complete data log likelihood를 정의하고 이를 최대화하자\n",
    "* 그럼에도 latent variable을 관측할 수 없고, 확률 분포가 multimodal일 수도 있어서 analytically하게 최적화 못함 \n",
    "\n",
    "![](./images/ch17/37.png)\n",
    "\n",
    "\n",
    "* 최초 guess -> 기대값 -> 기대값 최대화하게 guess 갱신 -> 수렴할 때까지 반복\n",
    "* data log likelihood는 매 iteration마다 단조 증가한다. \n",
    "\n",
    "![](./images/ch17/38.png)\n",
    "![](./images/ch17/39.png)\n",
    "\n",
    "\n",
    "### 주의할 점\n",
    "* gaussian family와 같은 특수한 형태가 되야지 E-step, M-step이 analytically, close-form으로 풀린다.\n",
    "* 구한 MLE는 local maxima일 수 있다. \n",
    "  \n",
    "  \n",
    "### 예제 - EM for GMM\n",
    "\n",
    "![](./images/ch17/42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.2 EM for HMMs (Baum-Welch Algorithm)\n",
    "---\n",
    "* 상태열을 모를 때 (당연!)\n",
    "\n",
    "\n",
    "#### E-step\n",
    "---\n",
    "* forward-backward algorithm 을 통해 얻을 수 있다.\n",
    "\n",
    "![](./images/ch17/40.png)\n",
    "![](./images/ch17/41.png)\n",
    "\n",
    "\n",
    "#### M-step\n",
    "\n",
    "* 최초 상태 확률과 천이 확률은 아래처럼 단순히 normalization이다. \n",
    "  * 아래 링크처럼 auxiliary function이 최적화 목적함수이고, 라그랑제 multiplier를 이용하면 유도된다.\n",
    "  * https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf\n",
    "  \n",
    "![](./images/ch17/43.png)\n",
    "\n",
    "* 관측 확률은 multinoulli model인 경우 \n",
    "  * 상태 j에 머물르면서 관측 l을 할 기대 count를 normaliza 한 것\n",
    "\n",
    "![](./images/ch17/45.png)\n",
    "![](./images/ch17/44.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.2.3 Initailization of parameters\n",
    "\n",
    "초기화가 어설프면 poor local minima에서 헤어나오지 못한다. \n",
    "\n",
    "실용적인 방법들\n",
    "* 조금이라도 fully labeled data가 있으면 이걸 가지고 naive하게나마 초기 파라미터 값을 정한다. (17.5.1)\n",
    "* markov 속성을 무시하고, 그냥 k-means 와 같은 방법으로 추정 \n",
    "* 그냥 무식하게 random multiple restart한다. \n",
    "\n",
    "\n",
    "deterministic annealing 으로 local minima 완화 \n",
    "* http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.522.8071&rep=rep1&type=pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.3 Baysian methods for fitting HMMs *  - SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.4 Discriminative traning  - 포기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.5 Model selection\n",
    "\n",
    "hidden state 몇개 쓸까? state transition topology를 어떻게 할까?\n",
    "\n",
    "\n",
    "#### 17.5.5.1 Choosing the number of hidden states\n",
    "---\n",
    "\n",
    "11.5.1 \n",
    "\n",
    "pick the model with the largest marginal likelihood, K_star = argmax p(D|K)\n",
    "\n",
    "likelihood is intractable 이어서 approx 사용\n",
    "\n",
    "\n",
    "5.3.2.4\n",
    "\n",
    "AIC\n",
    "\n",
    "BIC \n",
    "\n",
    "혹은 CV에서는 cross-validated likelihood \n",
    "\n",
    "samplimg based\n",
    " = reversible jump MCMC\n",
    " - Dirichlet process, gibbs sampling\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.5.2 Structure learning - 포기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
