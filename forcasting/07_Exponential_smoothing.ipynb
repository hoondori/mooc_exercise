{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Simple exponential smoothing\n",
    "\n",
    "* trend나 seasonal pattern에 적용하는 것이 적당\n",
    "![](./images/ch07/04.png)\n",
    "\n",
    "* 과거일수록 더 가중치가 낮아지는 가중합\n",
    "![](./images/ch07/01.png)\n",
    "\n",
    "* 수학적으로는 아래처럼, 이전 step의 forcast를 현재 관측값과 가중합하는 것과 동치 \n",
    "![](./images/ch07/02.png)\n",
    "\n",
    "### Component form\n",
    "\n",
    "* only component included is the level(smoothed value), l(t)\n",
    "  * h = 1 이면 fitted value\n",
    "  * t = T 이면 flat forcast\n",
    "  \n",
    "![](./images/ch07/03.png)\n",
    "\n",
    "### 최적화\n",
    "\n",
    "* 위의 component form을 적용하려면, alpha와 l(0)가 parameter\n",
    "* 예를 들어 SSE를 최소화하는 최적 파라미터로서 구한다.\n",
    "\n",
    "![](./images/ch07/05.png)\n",
    "\n",
    "### 예제 \n",
    "\n",
    "* 오일 예제에서 SSE 최소화를 만족시키는 최적값은 alpha=0.83, l(0)=446.6\n",
    "* 이를 이용해서 점화식에 대입하면\n",
    "  * t < T 까지는 fitted value\n",
    "  * t > T 부터는 flat forcast\n",
    "  \n",
    "![](./images/ch07/06.png)\n",
    "\n",
    "* alpha가 크면, 현재 관측값이 더 중요해져서, 더 sharp해지고\n",
    "* alpha가 작으면, 과거 level값이 중요해져서, 더 smooth해진다.\n",
    "![](./images/ch07/07.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Trend methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt’s linear trend method (1957)\n",
    "\n",
    "* a forecast equation and two smoothing equations (one for the level and one for the trend)\n",
    "* l(t) 는 현재 관측값인 y(t)와 one-step training forcast끼리의 가중합\n",
    "* b(t) 는 현재의 slope 관측값인 l(t) - l(t-1)과 이전 step의 slope 값 끼리의 가중합\n",
    "\n",
    "![](./images/ch07/08.png)\n",
    "\n",
    "#### 더 이상 flat forcast가 아니다. trendy한 forcast이다.\n",
    "![](./images/ch07/09.png)\n",
    "\n",
    "### Damped trend methods (1985)\n",
    "\n",
    "* holt의 방법은 무한히 상승(하강)하는 forcast라는 말도 안되는 결과가 나온다. (h가 크다면)\n",
    "* 이를 꺽는(dampen) 파리머터를 도입하자. \n",
    "* pi = 1이면 holt랑 동일\n",
    "![](./images/ch07/10.png)\n",
    "\n",
    "#### short horizon에서는 trended, longer horizon에서는 상수값으로 수렴\n",
    "![](./images/ch07/11.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Holt-Winters’ seasonal method (1960)\n",
    "\n",
    "* one forecast equation and three smoothing equations (level, trend, seasonal)\n",
    "\n",
    "### Holt-Winters’ additive method\n",
    "\n",
    "* seasonal variations are roughly constant through the series\n",
    "* The level equation shows a weighted average between the seasonally adjusted observation and the non-seasonal forecast for time t \n",
    "* The seasonal equation shows a weighted average between the current seasonal index, and the seasonal index of the same season last year\n",
    "\n",
    "![](./images/ch07/12.png)\n",
    "\n",
    "### 예제\n",
    "\n",
    "![](./images/ch07/13.png)\n",
    "![](./images/ch07/14.png)\n",
    "\n",
    "### Holt-Winters’ damped method\n",
    "\n",
    "* Holt-Winters’ multiplicative method + damping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 A taxonomy of exponential smoothing methods (1969)\n",
    "\n",
    "* Trend와 seasonal의 상황에 따라 3x3 = 9가지 경우의 수\n",
    "\n",
    "![](./images/ch07/15.png)\n",
    "![](./images/ch07/16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Innovations state space models for exponential smoothing\n",
    "\n",
    "* 지금까지는 point forcast이고, prediction interval은 없었다.\n",
    "* 이제 통계적 분석을 해보자\n",
    "* ETS(,,) = (Error, Trend, Seasonal) \n",
    "* Error는 Additive or Multiplicative\n",
    "\n",
    "### ETS(A,N,N): simple exponential smoothing with additive errors\n",
    "\n",
    "![](./images/ch07/17.png)\n",
    "![](./images/ch07/18.png)\n",
    "\n",
    "* (7.3) measurment equation은 관측읜 내재된 구성을 보여준다.\n",
    "  * 예측 가능한 부분은, level\n",
    "  * 예측 불가능한 부분은, error\n",
    "* (7.4) state equation\n",
    "  * 시간에 따라서 state가 evolve하는 것을 의미\n",
    "  * alpha값에 따라서 상태의 변화 정도가 조절\n",
    "  * alpha=0 이면, level이 전혀 변화지 않는 상태 \n",
    "  * alpha=1 이면, pure random walk\n",
    "\n",
    "### All methods\n",
    "\n",
    "![](./images/ch07/19.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Estimation and model selection\n",
    "\n",
    "### Estimating ETS models\n",
    "\n",
    "* 지금까지는 Mimimization of MSE 를 통해 parameter estimation을 보여줬음 \n",
    "  * 또다른 방법은 ML(maximum likelihood) 이다. \n",
    "  * Additive error 계열 방법은 MMSE나 ML이나 결과 동일하나, Multiplicative error 계열은 두 방법의 결과가 다르다.\n",
    "* 지금까지는 모든 파라미터는 0과 1사이로 제약(traditional constraint)을 두었다. \n",
    "  * state-space model에서는 이를 완화한(less restrictive)한 파라미터로 볼 수 있다. \n",
    "  * addimissible constraint,  \n",
    "  * ex) 0 < alpha < 2\n",
    "  \n",
    "### Model selection\n",
    "\n",
    "![](./images/ch07/20.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Forecasting with ETS models\n",
    "\n",
    "![](./images/ch07/21.png)\n",
    "![](./images/ch07/22.png)\n",
    "![](./images/ch07/23.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
