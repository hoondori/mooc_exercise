{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Time series regression models\n",
    "\n",
    "* forcast variable y가 predictor variable x에 선형적으로 관련성이 있다는 가정하에 모델링\n",
    "  * 예) 월별 판매량 y를, 광고 집행비 x로 선형적으로 설명\n",
    "* forcast variable\n",
    "  * regressand, dependent or explained \n",
    "* predictor variable\n",
    "  * regressors, independent or explanatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regresssion\n",
    "\n",
    "* slope, intercept, error\n",
    "  * 에러는 실제 에러가 아니라, x로 설명되지 않는 factor들의 종합적 영향을 표현하는 것\n",
    "\n",
    "![](./images/ch05/01.png)\n",
    "![](./images/ch05/02.png)\n",
    "\n",
    "\n",
    "### Example: US consumption expenditure\n",
    "\n",
    "* 가처분 소득 변화율(x)와 지출 변화율(y)\n",
    "\n",
    "![](./images/ch05/03.png)\n",
    "![](./images/ch05/04.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regresssion\n",
    "\n",
    "![](./images/ch05/05.png)\n",
    "\n",
    "### Example: US consumption expenditure\n",
    "\n",
    "* 다양한 predictor 고려\n",
    "  * 산업 생산량 변화, 저축률 변화, 실업율 변화\n",
    "  \n",
    "![](./images/ch05/06.png)\n",
    "\n",
    "* scatterplot으로 개별 predictor와 forcasting variable사이의 관련성, predictor들끼리의 상관성 도식화\n",
    "  * 소득 증가와, 산업 생산량 증가와는 +의 상관관계\n",
    "  * 저축률 증가와, 실업률 증가와는 -의 상관관계\n",
    "![](./images/ch05/07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error term에 대한 가정\n",
    "\n",
    "* zero mean을 가져야 한다. 아니라면 systematic bias가 생김\n",
    "* autocorrelated되지 말아야 한다. 아니라면 forcasting이 비효율적이 된다. \n",
    "* predictor들과는 unrelated되지 말아야 한다. 아니라면 model에 반영되야할 어떤 시스템적인 특성이 더 있다는 말이다. \n",
    "* gaussian 분포를 갖되 constant varience까지 갖는다면 prediction interval 구할 때 매우 도움이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Least squares estimation\n",
    "\n",
    "![](./images/ch05/08.png)\n",
    "\n",
    "![](./images/ch05/09.png)\n",
    "\n",
    "### Goodness-of-fit\n",
    "\n",
    "#### R-squared\n",
    "\n",
    "* square of the correlation between the observed yvalues and the predicted y_hat values.\n",
    "* reflects the proportion of variation in the forecast variable that is accounted for (or explained) by the regression model.\n",
    "  * 예를 들어 값이 0.74라면 74%의 variation을 설명하는 것이라고 볼 수 있다. \n",
    "* perfect fit이면 1, unrelated fit이라면 0\n",
    "\n",
    "![](./images/ch05/10.png)\n",
    "\n",
    "* 한계점 \n",
    "  * 부정확할 수 있다.\n",
    "    * predictor를 추가할 때마다 늘어만 간다. 절대 줄어들지 않는다. \n",
    "  * data마다 적절한 값 기준이 다르다. \n",
    "  * 이처럼 training data에 대한 R-squared값을 구하는 것보다는 test data에 대한 perf metric을 구하는 것이 훨씬 낫다. \n",
    "\n",
    "#### Standard error of regression\n",
    "\n",
    "* standard deviation of residuals\n",
    "* 에러의 누적 총량이 아니라 에러의 varience에 집중\n",
    "* k개의 predictor 개수로 보정\n",
    "\n",
    "![](./images/ch05/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Evaluating the regression model\n",
    "\n",
    "### residual\n",
    "* 관측값 - 예측값 \n",
    "* residual은 zero mean\n",
    "* redisual과 predictor와는 uncorrelated\n",
    "\n",
    "![](./images/ch05/12.png)\n",
    "![](./images/ch05/13.png)\n",
    "\n",
    "\n",
    "### ACF plot of residuals\n",
    "\n",
    "* 관측값은 autocorrelated가 강하다. 왜냐하면 previous(next) time 관측값은 current값과 연관이 있기 때문에\n",
    "* 마찬가지로 residual에서도 이러한 autocorrelation이 있는지를 조사하는 것이 중요 \n",
    "* 만약 autocorrelated되었다면\n",
    "  * 선형 모델링의 가정인 uncorrelated residual가정이 무너진다. \n",
    "  * 즉 시스템적으로 무언가 반영할 만한 정보가 있다는 뜻이고, 모델링이 덜 됬다는 신호\n",
    "  * 예측의 부정확성을 증가시키므로, prediction interval이 늘어나게 되는 결과 초래\n",
    "  \n",
    "![](./images/ch05/14.png)\n",
    "\n",
    "* Breusch-Godfrey test( or Lagrange Multiplier test) 를 통해 autocorrelated여부를 세밀하게 따지게 된다. \n",
    "  * 작은 p이면 uncorrelated\n",
    "\n",
    "![](./images/ch05/15.png)\n",
    "\n",
    "\n",
    "### Residual plots against predictors\n",
    "\n",
    "* 선형 모델에서는 predictor와 residual은 uncorrelated되어야 한다. \n",
    "* scatterplot을 통해서 이를 검증해 본다. \n",
    "* 만약 correlated되어 있다면, 더이상 선형 모델로는 부족하고, 비선형 모델링으로 전환해야 한다. \n",
    "\n",
    "![](./images/ch05/16.png)\n",
    "\n",
    "### Residual plots against fitted values\n",
    "\n",
    "* 어떤 패턴도 발견되서는 안된다. \n",
    "* 아니라면 소위, 에러 내에 이분산성(heteroscedasticity)이 있는 상황으로 의심됨 \n",
    "  * 에러의 varience가 x 값이 따라서 달라지는 현상\n",
    "\n",
    "![](./images/ch05/18.png)\n",
    "\n",
    "* 이분산성이란?\n",
    "  * variability of variable이 값에 따라서 달라지는 상황\n",
    "  * 아래 그림에서는 나이에 따른 소득 수준을 그린 것이다.\n",
    "  * 소득 편차는 나이대에 따라 다르다. 십대에서는 모두가 소득이 낮다. 하지만 20~30대 갈수록 빈부격차가 강화되고, 50~60대 가면 격차가 극에 달한다. \n",
    "  \n",
    "![](./images/ch05/17.png)\n",
    "\n",
    "\n",
    "### Outliers and influential observations\n",
    "\n",
    "* outlier란?\n",
    "  * extreme value \n",
    "* influential observation이란?\n",
    "  * 모델의 parameter값 결정에 많은 영향을 끼친 관측값들\n",
    "* outlier는 보통 influential하다고 말할 수 있다. \n",
    "\n",
    "![](./images/ch05/19.png)\n",
    "\n",
    "* outlier에 어떻게 대처할 것인가? \n",
    "  * 일단 어떻게 발견할 것인가? \n",
    "    * min/max와 같은 간단한 방법으로 수동 발견, scatterplot으로 눈대중으로, 좀더 정교한 통계 방법으로..\n",
    "  * unlikely outlier라고 판단되면 그냥 제거 \n",
    "    * 실제값이라기 보다는 잘못 기록된 값이라고 생각되면 제거 \n",
    "  * likely outlier라고 여거지면\n",
    "    * 제거한 경우의 fit과 제거하지 않은 경우의 fit 모두를 해보고 검토해 본다. \n",
    "    \n",
    "### Spurious regression\n",
    "\n",
    "* 시계열 데이터가 non-stationary한 경우도 있다. \n",
    "  * 즉 시간에 따라 분포가 달라진다 (change of mean, variance)\n",
    "  * 이런 경우 선형 모델에 미치는 영향은 어떻게 될까?\n",
    "* 비정적 시계열 데이터를 선형 모델링을 하면 Spurious regression이 된다. \n",
    "  * 과도한 R-sqaured와 autocorrelated residual이 관측\n",
    "  * 아래 예시에서는 서로 상관없는 기니의 쌀 생산량과 호주의 비행기 이용객 수를 억지로 선형 모델할 때 spurious regression이 생기는 경우 \n",
    "  \n",
    "![](./images/ch05/20.png)\n",
    "![](./images/ch05/21.png)\n",
    "![](./images/ch05/22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Some useful predictors\n",
    "\n",
    "### Trend\n",
    "\n",
    "* x=t \n",
    "\n",
    "![](./images/ch05/23.png)\n",
    "\n",
    "### Dummy variable\n",
    "\n",
    "* predictor가 numeric이 아닌 categorical인 경우 \n",
    "* 예를 들어 Holiday 인지 아닌지, Yes or No\n",
    "* indicator variable로 변환하여 선형 모델에 반영\n",
    "\n",
    "### Seasonal dummy variables\n",
    "\n",
    "* 카테고리수가 3개 이상인 경우는 one-hot encoding을 한다. \n",
    "* all zero를 포함하므로 predictor의 개수는 카테고리수 - 1 \n",
    "* 해석\n",
    "  * measure of the effect of that category relative to the omitted category\n",
    "  * 요일 예시에서는 ommit된 일요일 대비한 효과\n",
    "\n",
    "\n",
    "![](./images/ch05/24.png)\n",
    "\n",
    "### Example: Australian quarterly beer production\n",
    "* 1개의 trend와 3개의 querterly variable (첫번째 쿼터 ommitted)\n",
    "\n",
    "![](./images/ch05/25.png)\n",
    "![](./images/ch05/27.png)\n",
    "![](./images/ch05/28.png)\n",
    "\n",
    "### Intervention variables\n",
    "\n",
    "* 일종의 외부 개입 효과를 나타내는 predictor\n",
    "  * ex) 경쟁사의 행위, 광고 효과, 산업계의 행동\n",
    "* 일회성이면 spike dummy variable로 묘사\n",
    "* 즉각적이며 영구적인 level-shift와 같은 효과가 되면 step variable로 묘사 \n",
    "* 영구적인 상승/하강 trend를 초래하면, piecewise linear로 묘사 \n",
    "\n",
    "\n",
    "### Distributed lags\n",
    "\n",
    "* 광고비와 같은 경우, 실제 효과는 늦게(lagged) 나타나는 predictor 이다. \n",
    "* 다음처럼 과거 집행한 광고비의 효과를 별도의 predictor로 묘사 \n",
    "\n",
    "![](./images/ch05/26.png)\n",
    "\n",
    "\n",
    "### Fourier series\n",
    "\n",
    "* 좀 더 긴 주기의 periodical한 시게열 데이터를 fit하는데 좋음 \n",
    "* quarterly data의 경우는 년간 4개의 data point밖에 없는 경우므로, seasonal dummy variable이 더 효과적\n",
    "* 반면, weekly data in a year의 경우는 m=52이므로, 푸리에로 fit하는게 더 적은 variable로 fit할 수 있음 \n",
    "\n",
    "![](./images/ch05/29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Selecting predictors\n",
    "\n",
    "* predictor들이 넘처나는데 어떻게 고를 것인가?\n",
    "* 권장하지 않는 접근법\n",
    "  * 하나의 predictor와 forcasting 변수 사이의 상관 관계를 단순 파악하고(ex. scatterplot), 그냥 버려버리는 경우\n",
    "  * fit을 돌려서 나온 p-value를 맹신해서 쉽게 버리는 경우 \n",
    "    * p-value는 misleading할 수 있다. \n",
    "* CV()함수를 사용해서 나온 metric들로 판단해보자 \n",
    "\n",
    "### Adjusted R-squared\n",
    "\n",
    "* R-squared 의 단점인 predictor추가시에 값이 무조건 증가하는 현상을 해소\n",
    "\n",
    "![](./images/ch05/30.png)\n",
    "\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "* leave-one-out cross-validation to selection predictors \n",
    "\n",
    "### Akaike’s Information Criterion\n",
    "\n",
    "* data fit와 동시에 model parameter 개수 최소화(small model 선호) \n",
    "\n",
    "![](./images/ch05/31.png)\n",
    "\n",
    "### Corrected Akaike’s Information Criterion\n",
    "\n",
    "* AIC는 large T일 경우에만 유효\n",
    "* small T인 경우는 predictor 개수 억제 효과가 사라짐\n",
    "* Correlated AIC는 larget T 제약을 완화시켜서, small T인 경우에도 동작\n",
    "  * https://www.researchgate.net/publication/242197194_171290_Model_Selection_Lecture_III_AIC_and_Corrected_AIC_AICc\n",
    "* large T라면, AIC와 비슷해진다. \n",
    "\n",
    "![](./images/ch05/32.png)\n",
    "\n",
    "\n",
    "### Schwarz’s Bayesian Information Criterion\n",
    "\n",
    "* AIC보다 predictor 개수 억제 효과가 더 있다. \n",
    "\n",
    "![](./images/ch05/33.png)\n",
    "\n",
    "### Which measure should we use?\n",
    "\n",
    "* 일반적으로 Adjusted R-squared를 많이 쓰지만. too many predictor가 선택되는 경향 있음 \n",
    "* 통계학자들은 대부분 BIC를 선호, true underlying model을 찾는 것이라고 생각하므로 \n",
    "* 하지만 현실적으로는 true model이 좋은 forcasting을 하는 것은 아니다. \n",
    "* 저자의 추천은 AIC, AICc, CV\n",
    "\n",
    "### 예시 : 미국 소비율 문제\n",
    "\n",
    "* predictor 후보 4개의 조합을 생각하면 총 16개의 모델 가능, 이를 위의 metric으로 측정해 보면 \n",
    "* 얼핏 보면 4개 다 쓴게 가장 좋아 보이나..\n",
    "  * 처음 네 개 row가 나머지보다 훨씬 낫다. => 즉 income하고, saving이 나머지보다 중요\n",
    "  * 처음 두 개 row가 거의 비슷하다. => 즉 production은 있으나마나\n",
    "  * 결론적으로는 production빼고 3개 정도 있으면 될 듯\n",
    "![](./images/ch05/34.png)\n",
    "\n",
    "\n",
    "### stepwise regression\n",
    "\n",
    "* 변수가 너무 많은 경우, 예를 들어 40개의 변수라면, 가능 모델은 2^40\n",
    "* backward-stepwise regression\n",
    "  * 모든 변수를 쓴 모델에서 출발해서, 하나를 뺄 때 개선 효과가 있으면 빼고 아니면 그대로, 이를 반복\n",
    "  * 이것도 변수가 매우 많으면 못할 짓 \n",
    "* forward-stepwise regression\n",
    "  * 1변수부터 시작해서 하나를 더할 때 개선 효과가 있으면 더하고 아니면 그대로, 이를 반복 \n",
    "* hybrid \n",
    "  * 적절 모델에서 출발해서, forward/backward를 혼합해서 \n",
    "* 위 모든 방법은 best model로 귀결을 보장하지는 않지만 적절한 개선 모델로는 나아간다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Forecasting with regression\n",
    "\n",
    "### Ex-ante versus ex-post forecasts\n",
    "\n",
    "* Ex-ante forcast\n",
    "  * before the fact\n",
    "  * 해당 시점까지 주어진 fact만을 가지고 forcast를 하는 것 \n",
    "  * forcast of predictor가 필요 \n",
    "    * ex) 미국 소비율 forcast의 경우, y_t를 예측하려면 x_t가 있어야 하나, x_t는 현재 없는 상황\n",
    "      * 이 경우 x_t-1로 x_t를 추정한 후, 이를 바탕으로 y_t를 추정\n",
    "  * 진짜 예측이라고 볼 수 있다.\n",
    "* Ex-post forcast\n",
    "  * after the fact\n",
    "  * 미래의 fact도 동원해서라도 forcast를 하는 것\n",
    "  * 실제 예측이라기 보다는 forcasting model의 연구를 위한 방법\n",
    "  \n",
    "#### Example: Australian quarterly beer production\n",
    "\n",
    "* 호주 맥주량 예측의 경우, predictor가 deterministic한 것이라서(즉 forcast of predictor가 가능해서) \n",
    "  * Ex-ante와 Ex-post가 같은 경우이다. \n",
    "\n",
    "![](./images/ch05/35.png)\n",
    "![](./images/ch05/36.png)\n",
    "\n",
    "### Building a predictive regression model\n",
    "\n",
    "* 아예 미래를 예측하는 선형 모델을 만들어 버리면, ex-ante forcast에 대한 고민이 없지 않을까?\n",
    "* 광고비 집행 예시처럼 효과가 늦게 나타나는 경우도 더 잘 설명 가능할 것이다. \n",
    "\n",
    "![](./images/ch05/37.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
