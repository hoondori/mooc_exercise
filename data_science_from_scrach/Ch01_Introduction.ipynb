{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is data science\n",
    "\n",
    "extract insights from messy data\n",
    "\n",
    "set up hypothesis and evaluate it\n",
    "\n",
    "identify hidden patterns\n",
    "\n",
    "predict the future with hypothesized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'name': 'Hero'}\n"
     ]
    }
   ],
   "source": [
    "# define data scientist network\n",
    "\n",
    "users = [\n",
    "    { \"id\": 0, \"name\": \"Hero\" },\n",
    "    { \"id\": 1, \"name\": \"Dunn\" },\n",
    "    { \"id\": 2, \"name\": \"Sue\" },\n",
    "    { \"id\": 3, \"name\": \"Chi\" },\n",
    "    { \"id\": 4, \"name\": \"Thor\" },\n",
    "    { \"id\": 5, \"name\": \"Clive\" },\n",
    "    { \"id\": 6, \"name\": \"Hicks\" },\n",
    "    { \"id\": 7, \"name\": \"Devin\" },\n",
    "    { \"id\": 8, \"name\": \"Kate\" },\n",
    "    { \"id\": 9, \"name\": \"Klein\" }\n",
    "]\n",
    "\n",
    "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "(4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
    "\n",
    "print( users[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![network](./images/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What's average number of connections ?\n",
    "\n",
    "# construct friend map\n",
    "for user in users:\n",
    "    user[\"friends\"] = []\n",
    "for i, j in friendships:\n",
    "    users[i][\"friends\"].append(users[j]) # add i as a friend of j\n",
    "    users[j][\"friends\"].append(users[i]) # add j as a friend of i\n",
    "    \n",
    "def number_of_friends(user):\n",
    "    \"\"\"how many friends does _user_ have?\"\"\"\n",
    "    return len(user[\"friends\"])\n",
    "\n",
    "total_connections = sum(number_of_friends(user) for user in users)\n",
    "\n",
    "assert total_connections == 24\n",
    "\n",
    "from __future__ import division  # integer division is lame\n",
    "num_users = len(users) # length of the users list\n",
    "avg_connections = total_connections / num_users \n",
    "\n",
    "assert avg_connections == 2.4     # <-- This is answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 3), (3, 3), (5, 3), (8, 3), (0, 2), (4, 2), (6, 2), (7, 2), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "# find most influential person ( i.e most connected person )\n",
    "\n",
    "# create a list (user_id, number_of_friends)\n",
    "num_friends_by_id = [(user[\"id\"],number_of_friends(user)) for user in users]\n",
    "\n",
    "# sort the list\n",
    "sorted_result = sorted(num_friends_by_id,\n",
    "                       key=lambda (user_id, num_friends): num_friends,  # sort key\n",
    "                       reverse=True\n",
    "                      )\n",
    "print(sorted_result)\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# as a degree of centraility\n",
    "## but.. is id 4 central\n",
    "\n",
    "![network](./images/2.png)\n",
    "\n",
    "## Do better in Ch 21. Network analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2, 5: 1})\n"
     ]
    }
   ],
   "source": [
    "# Data Scientists You may know ( a friends of friends )\n",
    "\n",
    "def friends_of_friend_ids_bad(user):\n",
    "    # \"foaf\" is short for \"friend of a friend\"\n",
    "    return [foaf[\"id\"]\n",
    "            for friend in user[\"friends\"] # for each of user's friends\n",
    "            for foaf in friend[\"friends\"] # get each of _their_ friends\n",
    "           ]\n",
    "\n",
    "assert friends_of_friend_ids_bad(users[0]) == [0,2,3,0,1,3]    # 0 included twice\n",
    "\n",
    "# remove duplicates\n",
    "from collections import Counter\n",
    "def not_the_same(user, other_user):\n",
    "    \"\"\"two usrs are not the same if they have different ids\"\"\"\n",
    "    return user[\"id\"] != other_user[\"id\"]\n",
    "def not_friends(user,other_user):\n",
    "    \"\"\"other user is not a friend if he's not in user[friend] \n",
    "       that is, if th's not_the_same as all the people in user[friends]\n",
    "    \"\"\"\n",
    "    return all(not_the_same(friend,other_user) for friend in user[\"friends\"])\n",
    "def friends_of_friend_ids(user):\n",
    "    return Counter(foaf[\"id\"]\n",
    "                   for friend in user[\"friends\"] # for each of my friends\n",
    "                   for foaf in friend[\"friends\"] # count their friends\n",
    "                   if not_the_same(user, foaf)   # who are not me\n",
    "                   and not_friends(user,foaf)    # and aren't my friends\n",
    "                  )\n",
    "\n",
    "assert friends_of_friend_ids_bad(users[3]) == [0, 2, 3, 0, 1, 3, 3, 5]\n",
    "print(friends_of_friend_ids(users[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({9: 3, 1: 2, 8: 1, 5: 1})\n"
     ]
    }
   ],
   "source": [
    "# find users with a common interest\n",
    "\n",
    "interests = [\n",
    "    (0, \"Hadoop\"), (0, \"Big Data\"), (0, \"HBase\"), (0, \"Java\"),\n",
    "    (0, \"Spark\"), (0, \"Storm\"), (0, \"Cassandra\"),\n",
    "    (1, \"NoSQL\"), (1, \"MongoDB\"), (1, \"Cassandra\"), (1, \"HBase\"),\n",
    "    (1, \"Postgres\"), (2, \"Python\"), (2, \"scikit-learn\"), (2, \"scipy\"),\n",
    "    (2, \"numpy\"), (2, \"statsmodels\"), (2, \"pandas\"), (3, \"R\"), (3, \"Python\"),\n",
    "    (3, \"statistics\"), (3, \"regression\"), (3, \"probability\"),\n",
    "    (4, \"machine learning\"), (4, \"regression\"), (4, \"decision trees\"),\n",
    "    (4, \"libsvm\"), (5, \"Python\"), (5, \"R\"), (5, \"Java\"), (5, \"C++\"),\n",
    "    (5, \"Haskell\"), (5, \"programming languages\"), (6, \"statistics\"),\n",
    "    (6, \"probability\"), (6, \"mathematics\"), (6, \"theory\"),\n",
    "    (7, \"machine learning\"), (7, \"scikit-learn\"), (7, \"Mahout\"),\n",
    "    (7, \"neural networks\"), (8, \"neural networks\"), (8, \"deep learning\"),\n",
    "    (8, \"Big Data\"), (8, \"artificial intelligence\"), (9, \"Hadoop\"),\n",
    "    (9, \"Java\"), (9, \"MapReduce\"), (9, \"Big Data\")\n",
    "]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# interest -> list of users\n",
    "user_ids_by_interest = defaultdict(list)\n",
    "for user_id,interest in interests:\n",
    "    user_ids_by_interest[interest].append(user_id)\n",
    "\n",
    "# user id -> list of interests\n",
    "interests_by_user_id = defaultdict(list)\n",
    "for user_id, interest in interests:\n",
    "    interests_by_user_id[user_id].append(interest)\n",
    "\n",
    "# find who has the most interest in common with a given user\n",
    "def most_common_interests_with(user):\n",
    "    return Counter(interested_user_id\n",
    "                    for interest in interests_by_user_id[user[\"id\"]]\n",
    "                    for interested_user_id in user_ids_by_interest[interest]\n",
    "                    if interested_user_id != user[\"id\"]\n",
    "                  )\n",
    "\n",
    "print(most_common_interests_with(users[0]))  # check most common sharing person is 9\n",
    "\n",
    "\n",
    "# Do better in Chapter 22. Recommnedation System \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relationship between salaries and experience\n",
    "\n",
    "salaries_and_tenures = [(83000, 8.7), (88000, 8.1),\n",
    "(48000, 0.7), (76000, 6),\n",
    "(69000, 6.5), (76000, 7.5),\n",
    "(60000, 2.5), (83000, 10),\n",
    "(48000, 1.9), (63000, 4.2)]\n",
    "\n",
    "# is it linearly dependent ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![network](./images/3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'more than five': 79166.66666666667, 'between two and five': 61500.0, 'less than two': 48000.0}\n"
     ]
    }
   ],
   "source": [
    "# find linearity between salaries and experince by bucketted histogram\n",
    "\n",
    "def tenure_bucket(tenure):\n",
    "    if tenure < 2:\n",
    "        return \"less than two\"\n",
    "    elif tenure < 5:\n",
    "        return \"between two and five\"\n",
    "    else:\n",
    "        return \"more than five\"\n",
    "    \n",
    "salary_by_tenure_bucket = defaultdict(list)\n",
    "for salary, tenure in salaries_and_tenures:\n",
    "    bucket = tenure_bucket(tenure)\n",
    "    salary_by_tenure_bucket[bucket].append(salary)\n",
    "\n",
    "average_salary_by_bucket = {\n",
    "    tenure_bucket : sum(salaries) / len(salaries)\n",
    "    for tenure_bucket, salaries in salary_by_tenure_bucket.iteritems()\n",
    "}\n",
    "\n",
    "print(average_salary_by_bucket)\n",
    "\n",
    "\n",
    "# Do better in Chapter 14. Simple Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning 3\n",
      "java 3\n",
      "python 3\n",
      "big 3\n",
      "data 3\n",
      "hbase 2\n",
      "regression 2\n",
      "cassandra 2\n",
      "statistics 2\n",
      "probability 2\n",
      "hadoop 2\n",
      "networks 2\n",
      "machine 2\n",
      "neural 2\n",
      "scikit-learn 2\n",
      "r 2\n"
     ]
    }
   ],
   "source": [
    "# word count on interests\n",
    "\n",
    "words_and_counts = Counter(word\n",
    "                           for user, interest in interests\n",
    "                           for word in interest.lower().split())\n",
    "\n",
    "for word, count in words_and_counts.most_common():\n",
    "    if count > 1:\n",
    "        print word, count\n",
    "        \n",
    "# Do better in Ch 20 Natural Lanauge Processing        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
