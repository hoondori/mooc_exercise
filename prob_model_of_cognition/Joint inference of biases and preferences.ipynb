{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint inference of biases and preferences\n",
    "\n",
    "* 원래 기본적인 IRL은 agent가 optimal하게 행동할 것을 가정으로 추론\n",
    "* time-inconsistency나 myopic agent의 sub-optimal한 행동을 바탕으로도 IRL 시도\n",
    "\n",
    "## Formalization of Joint Inference\n",
    "\n",
    "* 아래 나열한 모든 parameter가 IRL 의 대상이다.\n",
    "\n",
    "![](./images/joint/01.png)\n",
    "![](./images/joint/02.png)\n",
    "\n",
    "* 주어진 행동열을 바탕으로 prior를 시작으로 반복적으로 belief update를 한다.\n",
    "\n",
    "![](./images/joint/03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from Procrastinators\n",
    "\n",
    "* 예를 들어 아래처럼 계속해서 할 일을 데드라인 전까지 계속 미루는 행동열을 보고 파라미터들을 추정해 보자\n",
    "  * Task 수행 보상을 얼마나 될까?\n",
    "  * Exploration의 정도를 나타내는 softmax action noise는 얼마나 될까?\n",
    "  * Discount rate, k는 어느 정도일까?\n",
    "  * 데드라인 직전(lastMinute)에 Task를 수행할지 말지의 예측 확률?\n",
    "\n",
    "![](./images/joint/04.png)\n",
    "\n",
    "\n",
    "* Optimal model 인 경우\n",
    "  * D-2까지 일을 안한 것으로 보아 reward < workCost 로 판단. 즉 task보상이 너무 형편없어서 안하는 게 optimal \n",
    "  * 시간이 지남에 따라 Reward에 대한 기대치가 낮아짐\n",
    "  * 데드라인 직전(lastMinute)에 Task를 수행할 확률도 시간이 지남에 따라 급격히 낮아질 것임\n",
    "  * discount는 없음\n",
    "* Possibly discounting의 경우 \n",
    "  * 데드라인 직전(lastMinute)에 Task를 수행할 확률이 0보다는 크다. 약 0.2 \n",
    "  * 0.2 로 작은 이유 (왜 1.0이 아닌가?)\n",
    "    * possibly discounting 이므로 optimal agent가 되는 경우도 있으므로\n",
    "    * discount k가 생각보다 커서, reward < workCost 가 되는 경우도 있으므로\n",
    "\n",
    "* 마지막날 보니 실제 일했다!\n",
    "  * optimal 인 경우 \n",
    "    * reward에 대한 생각을 급격히 바꾸어야(revise) 한다. 알고보니 보상이 좋은 일이었군~\n",
    "    * action noise가 굉장히 클수도 있겠군~, 즉 reward < workCost가 확실하지만 action이 noisy해서 어쩌다가 일한 셈~\n",
    "  * possible discounting 인 경우 \n",
    "    * action noise에 대한 생각은 크게 변함이 없다. \n",
    "    * reward에 대한 생각은 급격히 바뀐다.\n",
    "\n",
    "![](./images/joint/05.png)\n",
    "![](./images/joint/06.png)\n",
    "![](./images/joint/07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant Choice: Time-inconsistent vs. optimal MDP agents\n",
    "\n",
    "### Naive path 를 관측 행동열로 할 때 \n",
    "\n",
    "* Veg를 향해 북쪽으로 가다가 Donut 가게 앞에서 즉각적 보상이 너무 크게 느껴져서 도넛 가게로 쏘옥 들어간 경로 \n",
    "* naive agent 일까? sophisicated agent일까? \n",
    "  * => naive 일 것이다. \n",
    "  \n",
    "![](./images/joint/08.png)\n",
    "\n",
    "* utility는 어떻게 될까? 특히 veg util 과 donut util의 차이 \n",
    "  * => prior는 N(0,1), posterior는 약 10정도에서 peak\n",
    "    \n",
    "![](./images/joint/09.png)\n",
    "\n",
    "* donutTempting\n",
    "  * 첫 위치에서는 donut보다 veg선호, 그러나 도넛가게 바로 앞에서는 도넛을 더 선호\n",
    "  * 첫 위치에서는 도넛 유혹이 없을 줄 알았는데, 결국 매우 강력한 도넛 유혹을 느꼈다.\n",
    "\n",
    "![](./images/joint/10.png)\n",
    "![](./images/joint/11.png)\n",
    "\n",
    "### sophisticated path 를 관측 행동열로 할 때 \n",
    "\n",
    "* 초반에 우회전해서 길게 돌아가서 Veg로 가는 행동열\n",
    "* naive agent 일까? sophisicated agent일까? \n",
    "  * => sophisicated 일 것이다. \n",
    "\n",
    "![](./images/joint/12.png)\n",
    "\n",
    "* utility는 어떻게 될까? 특히 veg util 과 donut util의 차이 \n",
    "  * => prior는 N(0,1), posterior는 약 10~20 정도에서 peak\n",
    "    \n",
    "![](./images/joint/13.png)\n",
    "\n",
    "* donutTempting\n",
    "  * naive path와 거의 동일하게 유혹이 있었다??\n",
    "\n",
    "![](./images/joint/14.png)\n",
    "\n",
    "\n",
    "### Veg로 곧장 가는 path 를 관측 행동열로 할 때 \n",
    "\n",
    "![](./images/joint/15.png)\n",
    "![](./images/joint/16.png)\n",
    "![](./images/joint/17.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
